{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e77081",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37a63f0",
   "metadata": {},
   "source": [
    "Agent Framework has been installed in the previous step. If it has not been installed, please run the following command in the terminal to install it.\n",
    "\n",
    "```\n",
    "# Install core framework\n",
    "pip install agent-framework\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40b704",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0ee44",
   "metadata": {},
   "source": [
    "Install the Microsoft Agent Framework packages. The framework is modular - you can install just what you need.\n",
    "\n",
    "Import required libraries for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from typing import Annotated\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Microsoft Agent Framework core\n",
    "from agent_framework import ChatAgent, ChatMessage, TextContent, Role\n",
    "\n",
    "# Azure integrations\n",
    "from agent_framework.azure import AzureOpenAIChatClient, AzureAIAgentClient\n",
    "from azure.identity.aio import DefaultAzureCredential, AzureCliCredential\n",
    "\n",
    "# Tool decorators\n",
    "from agent_framework import ai_function\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb061d",
   "metadata": {},
   "source": [
    "Configure environment variables. You can use either Azure OpenAI or Azure AI Foundry endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd443e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check required environment variables\n",
    "print(\"Checking environment variables...\")\n",
    "\n",
    "# For Azure OpenAI\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "# For Azure AI Foundry\n",
    "azure_project_endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "azure_ai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "if azure_openai_endpoint and azure_openai_deployment:\n",
    "    print(\"âœ“ Azure OpenAI configuration found\")\n",
    "    SERVICE_TYPE = \"azure_openai\"\n",
    "else:\n",
    "    print(\"âŒ Missing required environment variables!\")\n",
    "    print(\"\\nFor Azure OpenAI, set:\")\n",
    "    print(\"  - AZURE_OPENAI_ENDPOINT\")\n",
    "    print(\"  - AZURE_OPENAI_API_KEY\")\n",
    "    print(\"  - AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "    print(\"\\nOR for Azure AI Foundry, set:\")\n",
    "    print(\"  - AZURE_AI_PROJECT_ENDPOINT\")\n",
    "    print(\"  - AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "    \n",
    "print(f\"\\nUsing service: {SERVICE_TYPE}\")\n",
    "azure_openai_deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f284bc6",
   "metadata": {},
   "source": [
    "# Case 1: Basic Agent Creation and Execution\n",
    "\n",
    "In Microsoft Agent Framework, creating an agent is straightforward. Unlike Semantic Kernel which requires a Kernel instance, Agent Framework agents are created directly from chat clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e4e66",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 1.1: Simple Agent with Azure OpenAI\n",
    "---\n",
    "Create a basic ChatAgent using AzureOpenAIChatClient. The agent handles thread management automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat client and agent with Azure OpenAI\n",
    "azure_openai_chat_client = AzureOpenAIChatClient(\n",
    "    deployment_name=azure_openai_deployment,\n",
    "    endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    api_version=azure_openai_version\n",
    ")\n",
    "\n",
    "# Create an agent - no Kernel needed!\n",
    "agent = ChatAgent(\n",
    "    chat_client=azure_openai_chat_client,\n",
    "    instructions=\"You are a helpful assistant that provides concise, informative answers.\",\n",
    "    name=\"SimpleAssistant\"\n",
    ")\n",
    "\n",
    "# Run the agent with a simple question\n",
    "async def run_simple_agent():\n",
    "    result = await agent.run(\"Tell me about Microsoft in 3 sentences.\")\n",
    "    print(f\"Agent: {result.text}\")\n",
    "\n",
    "await run_simple_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4c219",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 1.2: Streaming Response\n",
    "---\n",
    "Agent Framework supports streaming responses for real-time output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40307b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_streaming_agent():\n",
    "    print(\"Agent: \", end=\"\", flush=True)\n",
    "    async for update in agent.run_stream(\"Tell me about Agentic AI in 3 sentences.\"):\n",
    "        if update.text:\n",
    "            print(update.text, end=\"\", flush=True)\n",
    "    print()  # New line after streaming\n",
    "\n",
    "await run_streaming_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d67e4c3",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 1.3: Multi-turn Conversation with Thread\n",
    "---\n",
    "Agents automatically maintain conversation context using threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def multi_turn_conversation():\n",
    "    \n",
    "    # Create a new thread.\n",
    "    thread = agent.get_new_thread()\n",
    "    \n",
    "    response1 = await agent.run(\"My name is Alex. I like programming in Python.\", thread=thread)\n",
    "    print(f\"Agent: {response1.text}\\n\")\n",
    "    \n",
    "    # Get the thread from the result\n",
    "    serialized = await thread.serialize()\n",
    "\n",
    "    # Later, deserialize and continue conversation\n",
    "    new_thread = await agent.deserialize_thread(serialized)\n",
    "    \n",
    "    # Second message - uses the same thread to maintain context\n",
    "    response2 = await agent.run(\"What is my name?\", thread=new_thread)\n",
    "    print(f\"Agent: {response2.text}\\n\")\n",
    "    \n",
    "    # Third message - agent remembers both previous exchanges\n",
    "    response3 = await agent.run(\"What programming language did I say I like?\", thread=new_thread)\n",
    "    print(f\"Agent: {response3.text}\")\n",
    "\n",
    "await multi_turn_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a440a2",
   "metadata": {},
   "source": [
    "# Case 2: Agents with Custom Tools/Functions\n",
    "---\n",
    "Agent Framework makes it easy to extend agents with custom functions using the @ai_function decorator.\n",
    "Define custom functions and register them with the agent. No plugin wrappers needed!\n",
    "\n",
    "* The @ai_function decorator is used to define Custom Functions that agents can call as simple Python functions, attaching metadata (name, description, parameter/return schemas, etc.) to register them with the agent. This allows extending agent capabilities with just function definitions, without separate plugin wrappers or complex class inheritance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b80208",
   "metadata": {},
   "source": [
    "### ðŸ§ª Case 2.1: Azure Open AI Client with Custom Function Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ce96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom functions using @ai_function decorator\n",
    "@ai_function(description=\"Get the current weather for a location\")\n",
    "def get_weather(location: Annotated[str, \"The city name\"]) -> str:\n",
    "    \"\"\"Returns mock weather data for the given location.\"\"\"\n",
    "    # In a real scenario, this would call a weather API\n",
    "    weather_data = {\n",
    "        \"Seoul\": \"Sunny, 22Â°C\",\n",
    "        \"New York\": \"Cloudy, 18Â°C\",\n",
    "        \"London\": \"Rainy, 15Â°C\",\n",
    "        \"Tokyo\": \"Clear, 20Â°C\",\n",
    "        \"Bangkok\": \"Hot, 30Â°C\"\n",
    "    }\n",
    "    return weather_data.get(location, f\"Weather data not available for {location}\")\n",
    "\n",
    "@ai_function(description=\"Get the current time in a timezone\")\n",
    "def get_time(timezone: Annotated[str, \"Timezone (e.g., 'UTC', 'EST', 'KST', 'SGT')\"]) -> str:\n",
    "    \"\"\"Returns mock time for the given timezone.\"\"\"\n",
    "    from datetime import datetime\n",
    "    # Simplified for demo - in production use proper timezone handling\n",
    "    return f\"Current time in {timezone}: {datetime.now().strftime('%H:%M:%S')}\"\n",
    "\n",
    "# Create an agent with these tools\n",
    "weather_agent = ChatAgent(\n",
    "    chat_client=azure_openai_chat_client,\n",
    "    instructions=\"You are a helpful assistant that can provide weather and time information.\",\n",
    "    name=\"WeatherAssistant\",\n",
    "    tools=[get_weather, get_time]\n",
    ")\n",
    "\n",
    "# Test the agent with tool calls\n",
    "async def test_tools():\n",
    "    result = await weather_agent.run(\"How is the weather in Bangkok?\")\n",
    "    print(f\"Agent: {result.text}\\n\")\n",
    "    \n",
    "    result2 = await weather_agent.run(\"What time is it in SGT?\")\n",
    "    print(f\"Agent: {result2.text}\")\n",
    "\n",
    "await test_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7310bf",
   "metadata": {},
   "source": [
    "# Case 4: Enterprise Tools with Azure AI Agent Client\n",
    "---\n",
    "Microsoft Agent Framework provides powerful enterprise-grade hosted tools that integrate seamlessly with Azure services. These tools enable agents to perform advanced operations like web search, document retrieval, and external integrations.\n",
    "\n",
    "## Hosted Tools Comparison\n",
    "\n",
    "| Tool | Purpose | Service | Key Features |\n",
    "|------|---------|---------|--------------|\n",
    "| **HostedFileSearchTool** | Document/Data Search | Azure AI Search | âœ… Index-based search<br>âœ… Semantic search<br>âœ… Configurable ranking |\n",
    "| **HostedWebSearchTool** | Real-time Web Search | Bing Grounding | âœ… Current information<br>âœ… Source citations<br>âœ… Web grounding |\n",
    "| **Local MCP** | Custom Integrations | Local Server | âœ… Full control<br>âœ… Custom logic<br>âœ… Local resources |\n",
    "| **Hosted MCP** | External Services | Remote Server | âœ… Third-party APIs<br>âœ… Scalable<br>âœ… Managed infrastructure |\n",
    "\n",
    "### Prerequisites for Practicing [Case 4]:\n",
    "\n",
    "Log in to your Azure account. (Please perform Azure CLI login in the terminal first.)\n",
    "- az login --use-device-code\n",
    "- az account set --subscription \"your-subscription-id\"\n",
    "\n",
    "### Check current login status and subscription\n",
    "- az account show --output table\n",
    "\n",
    "**For Azure AI Search (Case 4.1):**\n",
    "- Azure AI Search service with indexed data\n",
    "- Search connection configured in Azure AI Project\n",
    "- Index name (e.g., \"hotels-sample-index\")\n",
    "\n",
    "**For Bing Grounding (Case 4.2):**\n",
    "- Bing Grounding connection in Azure AI Project\n",
    "- `BING_CONNECTION_NAME` or `BING_CONNECTION_ID` environment variable\n",
    "\n",
    "**For MCP Tools (Case 4.3 & 4.4):**\n",
    "- Understanding of Model Context Protocol (MCP)\n",
    "- MCP server configuration (local or hosted)\n",
    "\n",
    "**In this training, we will proceed with Case 4.2 Bing Grounding. For the source code of other cases, please refer to the [original GitHub repository's Python code](https://github.com/Azure/agent-innovator-lab/blob/main/0_basic-agent/AgentFramework/1_basic-concept-with-msaf.ipynb).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a929708",
   "metadata": {},
   "source": [
    "* Note: For those who can not create Bing Grounding resource in Azure, please skip Case 4.1 and proceed to Case 4.3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d99553",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 4.2: Bing Grounding with HostedWebSearchTool\n",
    "---\n",
    "Demonstrates using Bing Search API for web grounding to answer questions with real-time web data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c7cff",
   "metadata": {},
   "source": [
    "**Setup:**\n",
    "- Azure AI Project with Bing Search connection\n",
    "- Environment variables: `AZURE_AI_PROJECT_ENDPOINT`, `BING_CONNECTION_NAME`\n",
    "\n",
    "**Key Modules:**\n",
    "- `HostedWebSearchTool` from `agent_framework.azure_ai.tools`\n",
    "- Provides grounded responses with web search results and citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from agent_framework.azure import AzureAIAgentClient, AzureOpenAIChatClient\n",
    "from agent_framework import HostedWebSearchTool\n",
    "from agent_framework import ChatAgent\n",
    "\n",
    "azure_project_endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "azure_ai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "async def bing_grounding_demo():\n",
    "    \"\"\"\n",
    "    Demonstrates using Bing Search API for web grounding to answer questions with real-time web data.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Get Azure AI Project endpoint\n",
    "        bing_connection_id = os.environ.get(\"BING_GROUNDING_CONNECTION_ID\")\n",
    "        \n",
    "        # Create Azure AI Agent client with credential\n",
    "        credential = AzureCliCredential()\n",
    "        \n",
    "        # Create web search tool with Bing connection\n",
    "        web_search_tool = HostedWebSearchTool(\n",
    "            \n",
    "            additional_properties={\n",
    "                \"connection_id\": bing_connection_id,\n",
    "                \"top_k\": 3,  # Get top 3 search results\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        azure_ai_agent_client = AzureAIAgentClient(\n",
    "            async_credential=credential,\n",
    "            project_endpoint=azure_project_endpoint,\n",
    "            model_deployment_name=azure_ai_deployment\n",
    "        )\n",
    "        \n",
    "        # Create agent with web search capability\n",
    "        agent = ChatAgent(\n",
    "            #chat_client=azure_openai_chat_client,\n",
    "            chat_client=azure_ai_agent_client,\n",
    "            name=\"Web Research Assistant\",\n",
    "            instructions=\"You are a helpful research assistant. Use web search to find current information and provide grounded answers with citations.\",\n",
    "            tools=[web_search_tool]\n",
    "        )\n",
    "        \n",
    "        # Test questions that require web search\n",
    "        USER_INPUTS = [\n",
    "            \"Tell me what day it is today and What is the latest exciting news in Bangkok?\"\n",
    "        ]\n",
    "        \n",
    "        print(\"=== Azure AI Agent with Bing Grounding Search ===\")\n",
    "        print(\"This agent can search the web for current information and provide grounded answers.\\n\")\n",
    "        \n",
    "        # Simulate conversation with the agent\n",
    "        for user_input in USER_INPUTS:\n",
    "            print(f\"User: {user_input}\")\n",
    "            print(\"Agent: \", end=\"\", flush=True)\n",
    "            \n",
    "            # Stream the response for better user experience\n",
    "            async for chunk in agent.run_stream(user_input):\n",
    "                if chunk.text:\n",
    "                    print(chunk.text, end=\"\", flush=True)\n",
    "            print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        \n",
    "        print(\"Web search conversation completed!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "    finally:\n",
    "        # Cleanup: Close Azure AI Agent client if it was created\n",
    "        try:\n",
    "            await azure_ai_agent_client.close()    \n",
    "        except Exception as cleanup_error:\n",
    "            print(f\"Cleanup warning: {cleanup_error}\")\n",
    "\n",
    "await bing_grounding_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee672e3c",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 4.3: Local MCP Server Integration\n",
    "---\n",
    "Demonstrates connecting to a local Model Context Protocol (MCP) server to extend agent capabilities with custom tools.\n",
    "\n",
    "### Setup:\n",
    "\n",
    "- Local MCP server running (e.g., file system tools, database connectors)\n",
    "- MCP server URL or configuration\n",
    "- Environment variable: AZURE_OPENAI_ENDPOINT\n",
    "\n",
    "### Key Modules:\n",
    "\n",
    "- Discovers and registers tools from MCP server dynamically\n",
    "- Works with any MCP-compliant server implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from agent_framework.azure import AzureOpenAIChatClient, AzureAIAgentClient\n",
    "from agent_framework import ChatAgent, MCPStreamableHTTPTool\n",
    "\n",
    "\n",
    "async def local_mcp_demo():\n",
    "    \"\"\"\n",
    "    Demonstrates connecting to a local Model Context Protocol (MCP) server \n",
    "    to extend agent capabilities with custom tools.\n",
    "    \n",
    "    This example shows how to use Microsoft Learn MCP server with Azure AI Agent.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create Azure AI Agent client with credential\n",
    "        credential = AzureCliCredential()\n",
    "        \n",
    "        print(\"=== Azure AI Agent with Local MCP Server ===\")\n",
    "        print(\"This agent can use MCP tools to access Microsoft documentation.\\n\")\n",
    "        \n",
    "        # Connect to local MCP server and create agent with MCP tools\n",
    "        async with (\n",
    "            AzureAIAgentClient(\n",
    "                async_credential=credential,\n",
    "                project_endpoint=azure_project_endpoint,\n",
    "                model_deployment_name=azure_ai_deployment\n",
    "            ) as azure_ai_agent_client,\n",
    "            MCPStreamableHTTPTool(\n",
    "                name=\"Local Microsoft Learn MCP\",\n",
    "                url=\"https://learn.microsoft.com/api/mcp\",\n",
    "            ) as mcp_server\n",
    "        ):\n",
    "            # Create agent with MCP tools\n",
    "            agent = ChatAgent(\n",
    "                chat_client=azure_ai_agent_client,\n",
    "                name=\"Local MCP Assistant(AzureAIAgentClient)\",\n",
    "                instructions=\"You are a helpful assistant that can help with Microsoft documentation questions using MCP tools.\",\n",
    "                tools=mcp_server,\n",
    "                store=True\n",
    "            )\n",
    "            \n",
    "            # Test questions that use MCP tools\n",
    "            USER_INPUTS = [\n",
    "                \"How to create an Azure storage account using az cli? response with a simple answer and an example.\",\n",
    "                \"What is Microsoft Agent Framework? response with key concepts and a main python code example.\"\n",
    "            ]\n",
    "            \n",
    "            # Simulate conversation with the agent\n",
    "            for user_input in USER_INPUTS:\n",
    "                print(f\"User: {user_input}\")\n",
    "                print(\"Agent: \", end=\"\", flush=True)\n",
    "                \n",
    "                # Stream the response for better user experience\n",
    "                async for chunk in agent.run_stream(user_input):\n",
    "                    if chunk.text:\n",
    "                        print(chunk.text, end=\"\", flush=True)\n",
    "                print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "            \n",
    "            print(\"MCP tool conversation completed!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "await local_mcp_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe959d",
   "metadata": {},
   "source": [
    "## ðŸ“Š Case 4 Comparison: Enterprise Tools\n",
    "\n",
    "| Feature | AI Search (4.1) | Bing Grounding (4.2) | Local MCP (4.3) | Hosted MCP (4.4) |\n",
    "|---------|----------------|---------------------|----------------|------------------|\n",
    "| **Tool Type** | `HostedFileSearchTool` | `HostedWebSearchTool` | `MCPClient` | `HostedMCPTool` |\n",
    "| **Client Type** | `AzureAIAgentClient` | `AzureAIAgentClient` | `AzureOpenAIChatClient` | `AzureAIAgentClient` |\n",
    "| **Data Source** | Azure AI Search vector stores | Bing Search API | Local MCP server process | Azure-hosted MCP server |\n",
    "| **Setup Complexity** | Medium (requires vector store) | Low (requires Bing connection) | Medium (requires local server) | Low (requires Azure connection) |\n",
    "| **Use Cases** | Internal document search, knowledge base | Real-time web information | Custom local tools, file system | Enterprise-grade custom tools |\n",
    "| **Authentication** | `DefaultAzureCredential` | `DefaultAzureCredential` | `AzureCliCredential` | `DefaultAzureCredential` |\n",
    "| **Grounding** | Citations from indexed docs | Web citations and sources | N/A (custom tool output) | Depends on MCP server |\n",
    "| **Scalability** | High (Azure managed) | High (Azure managed) | Low (local process) | High (Azure managed) |\n",
    "| **Customization** | Limited to indexed data | Limited to web search | Full (custom MCP tools) | Full (custom MCP tools) |\n",
    "| **Cost** | AI Search + AI Project | Bing API + AI Project | Azure OpenAI only | MCP hosting + AI Project |\n",
    "\n",
    "**Key Takeaways:**\n",
    "- AI Search (4.1): Best for searching through your own documents and knowledge bases with semantic search\n",
    "- Bing Grounding (4.2): Best for real-time web information with source citations\n",
    "- Local MCP (4.3): Best for development and testing with custom tools on local machine\n",
    "- Hosted MCP (4.4): Best for production deployment of custom tools with enterprise security and scalability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
