{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e77081",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37a63f0",
   "metadata": {},
   "source": [
    "ì´ì „ ë‹¨ê³„ì—ì„œ Agent Frameworkë¥¼ ì„¤ì¹˜í•˜ì˜€ìŠµë‹ˆë‹¤. ì„¤ì¹˜ê°€ ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•˜ì—¬ ì„¤ì¹˜í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "# Install core framework\n",
    "pip install agent-framework\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40b704",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0ee44",
   "metadata": {},
   "source": [
    "Import required libraries for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from typing import Annotated\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Microsoft Agent Framework core\n",
    "from agent_framework import ChatAgent, ChatMessage, TextContent, Role\n",
    "\n",
    "# Azure integrations\n",
    "from agent_framework.azure import AzureOpenAIChatClient, AzureAIAgentClient\n",
    "from azure.identity.aio import DefaultAzureCredential, AzureCliCredential\n",
    "\n",
    "# Tool decorators\n",
    "from agent_framework import ai_function\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb061d",
   "metadata": {},
   "source": [
    "í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. Microsoft Foundry ëª¨ë¸ì˜ endpointë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd443e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check required environment variables\n",
    "print(\"Checking environment variables...\")\n",
    "\n",
    "# For Azure OpenAI\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "# For Azure AI Foundry\n",
    "azure_project_endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "azure_ai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "if azure_openai_endpoint and azure_openai_deployment:\n",
    "    print(\"âœ“ Azure OpenAI configuration found\")\n",
    "    SERVICE_TYPE = \"azure_openai\"\n",
    "else:\n",
    "    print(\"âŒ Missing required environment variables!\")\n",
    "    print(\"\\nFor Azure OpenAI, set:\")\n",
    "    print(\"  - AZURE_OPENAI_ENDPOINT\")\n",
    "    print(\"  - AZURE_OPENAI_API_KEY\")\n",
    "    print(\"  - AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "    print(\"\\nOR for Azure AI Foundry, set:\")\n",
    "    print(\"  - AZURE_AI_PROJECT_ENDPOINT\")\n",
    "    print(\"  - AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "    \n",
    "print(f\"\\nUsing service: {SERVICE_TYPE}\")\n",
    "azure_openai_deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f284bc6",
   "metadata": {},
   "source": [
    "# Case 1: ê¸°ë³¸ Agent ìƒì„±ê³¼ ì‹¤í–‰\n",
    "\n",
    "Microsoft Agent Frameworkì—ì„œëŠ” ì—ì´ì „íŠ¸ ìƒì„±ì´ ë§¤ìš° ê°„ë‹¨í•©ë‹ˆë‹¤. Semantic Kernelì²˜ëŸ¼ Kernel ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìš”êµ¬í•˜ì§€ ì•Šê³ , ì±„íŒ… í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì§ì ‘ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e4e66",
   "metadata": {},
   "source": [
    "## ğŸ§ª Case 1.1: Azure OpenAIë¥¼ í™œìš©í•œ ê°„ë‹¨í•œ ì—ì´ì „íŠ¸\n",
    "---\n",
    "AzureOpenAIChatClientë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ë³¸ ChatAgentë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ëŠ” ìŠ¤ë ˆë“œ ê´€ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat client and agent with Azure OpenAI\n",
    "azure_openai_chat_client = AzureOpenAIChatClient(\n",
    "    deployment_name=azure_openai_deployment,\n",
    "    endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    api_version=azure_openai_version\n",
    ")\n",
    "\n",
    "# Create an agent - no Kernel needed!\n",
    "agent = ChatAgent(\n",
    "    chat_client=azure_openai_chat_client,\n",
    "    instructions=\"You are a helpful assistant that provides concise, informative answers.\",\n",
    "    name=\"SimpleAssistant\"\n",
    ")\n",
    "\n",
    "# Run the agent with a simple question\n",
    "async def run_simple_agent():\n",
    "    result = await agent.run(\"ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ì— ëŒ€í•´ì„œ í•œê¸€ 3ë¬¸ì¥ìœ¼ë¡œ ì–˜ê¸°í•´ì¤˜.\")\n",
    "    print(f\"Agent: {result.text}\")\n",
    "\n",
    "await run_simple_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4c219",
   "metadata": {},
   "source": [
    "## ğŸ§ª Case 1.2: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ\n",
    "---\n",
    "Agent Frameworkì€ ì‹¤ì‹œê°„ ì¶œë ¥ì„ ìœ„í•´ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì§€ì›í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40307b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_streaming_agent():\n",
    "    print(\"Agent: \", end=\"\", flush=True)\n",
    "    async for update in agent.run_stream(\"Agentic AIë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ì‰½ê²Œ ì„¤ëª…í•´ì¤˜.\"):\n",
    "        if update.text:\n",
    "            print(update.text, end=\"\", flush=True)\n",
    "    print()  # New line after streaming\n",
    "\n",
    "await run_streaming_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d67e4c3",
   "metadata": {},
   "source": [
    "## ğŸ§ª Case 1.3: ìŠ¤ë ˆë“œë¥¼ í™œìš©í•œ ë‹¤ì¤‘ í„´ (Multi-turn) ëŒ€í™”\n",
    "---\n",
    "ì—ì´ì „íŠ¸ëŠ” ìŠ¤ë ˆë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”ì˜ ë§¥ë½ì„ ìë™ìœ¼ë¡œ ìœ ì§€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def multi_turn_conversation():\n",
    "    \n",
    "    # Create a new thread.\n",
    "    thread = agent.get_new_thread()\n",
    "    \n",
    "    response1 = await agent.run(\"ë‚´ ì´ë¦„ì€ ì•Œë ‰ìŠ¤ì•¼. ë‚˜ëŠ” íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë§¹ì„ ì¢‹ì•„í•´.\", thread=thread)\n",
    "    print(f\"Agent: {response1.text}\\n\")\n",
    "    \n",
    "    # Get the thread from the result\n",
    "    serialized = await thread.serialize()\n",
    "\n",
    "    # Later, deserialize and continue conversation\n",
    "    new_thread = await agent.deserialize_thread(serialized)\n",
    "    \n",
    "    # Second message - uses the same thread to maintain context\n",
    "    response2 = await agent.run(\"ë‚´ ì´ë¦„ì´ ë­ì§€?\", thread=new_thread)\n",
    "    print(f\"Agent: {response2.text}\\n\")\n",
    "    \n",
    "    # Third message - agent remembers both previous exchanges\n",
    "    response3 = await agent.run(\"ë‚´ê°€ ì¢‹ì•„í•œë‹¤ê³  ë§í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\", thread=new_thread)\n",
    "    print(f\"Agent: {response3.text}\")\n",
    "\n",
    "await multi_turn_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a440a2",
   "metadata": {},
   "source": [
    "# Case 2: Custom Tools/Functions í™œìš©í•œ Agents \n",
    "---\n",
    "Agent Frameworkì€ `@ai_function` decoratorë¥¼ ì‚¬ìš©í•´ ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ë¥¼ ì†ì‰½ê²Œ í™•ì¥í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. \n",
    "\n",
    "* @ai_function ë°ì½”ë ˆì´í„°ëŠ” ì—ì´ì „íŠ¸ê°€ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” Custom Functionì„ ê°„ë‹¨í•œ íŒŒì´ì¬ í•¨ìˆ˜ë¡œ ì •ì˜í•˜ê³ , ë©”íƒ€ë°ì´í„°(ì´ë¦„, ì„¤ëª…, íŒŒë¼ë¯¸í„°/ë°˜í™˜ ìŠ¤í‚¤ë§ˆ ë“±)ë¥¼ ë¶€ì—¬í•´ ì—ì´ì „íŠ¸ì— ë“±ë¡í•˜ëŠ”ë° ì‚¬ìš©í•˜ëŠ” ë°ì½”ë ˆì´í„°ì…ë‹ˆë‹¤. ë³„ë„ì˜ í”ŒëŸ¬ê·¸ì¸ ë˜í¼ë‚˜ ë³µì¡í•œ í´ë˜ìŠ¤ ìƒì† ì—†ì´, í•¨ìˆ˜ ì •ì˜ë§Œìœ¼ë¡œ ì—ì´ì „íŠ¸ì˜ ëŠ¥ë ¥ì„ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b80208",
   "metadata": {},
   "source": [
    "### ğŸ§ª Case 2.1: Azure Open AI Client with Custom Function Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ce96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom functions using @ai_function decorator\n",
    "@ai_function(description=\"Get the current weather for a location\")\n",
    "def get_weather(location: Annotated[str, \"The city name\"]) -> str:\n",
    "    \"\"\"Returns mock weather data for the given location.\"\"\"\n",
    "    # In a real scenario, this would call a weather API\n",
    "    weather_data = {\n",
    "        \"Seoul\": \"Sunny, 22Â°C\",\n",
    "        \"New York\": \"Cloudy, 18Â°C\",\n",
    "        \"London\": \"Rainy, 15Â°C\",\n",
    "        \"Tokyo\": \"Clear, 20Â°C\"\n",
    "    }\n",
    "    return weather_data.get(location, f\"Weather data not available for {location}\")\n",
    "\n",
    "@ai_function(description=\"Get the current time in a timezone\")\n",
    "def get_time(timezone: Annotated[str, \"Timezone (e.g., 'UTC', 'EST', 'KST')\"]) -> str:\n",
    "    \"\"\"Returns mock time for the given timezone.\"\"\"\n",
    "    from datetime import datetime\n",
    "    # Simplified for demo - in production use proper timezone handling\n",
    "    return f\"Current time in {timezone}: {datetime.now().strftime('%H:%M:%S')}\"\n",
    "\n",
    "# Create an agent with these tools\n",
    "weather_agent = ChatAgent(\n",
    "    chat_client=azure_openai_chat_client,\n",
    "    instructions=\"You are a helpful assistant that can provide weather and time information.\",\n",
    "    name=\"WeatherAssistant\",\n",
    "    tools=[get_weather, get_time]\n",
    ")\n",
    "\n",
    "# Test the agent with tool calls\n",
    "async def test_tools():\n",
    "    result = await weather_agent.run(\"Seoulì˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?\")\n",
    "    print(f\"Agent: {result.text}\\n\")\n",
    "    \n",
    "    result2 = await weather_agent.run(\"KST ì‹œê°„ì€ ëª‡ ì‹œì¸ê°€ìš”?\")\n",
    "    print(f\"Agent: {result2.text}\")\n",
    "\n",
    "await test_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7310bf",
   "metadata": {},
   "source": [
    "# Case 4: Azure AI Agent Clientë¥¼ í™œìš©í•œ ì—”í„°í”„ë¼ì´ì¦ˆ ë„êµ¬\n",
    "---\n",
    "Microsoft Agent FrameworkëŠ” Azure ì„œë¹„ìŠ¤ì™€ ì›í• í•˜ê²Œ í†µí•©ë˜ëŠ” ê°•ë ¥í•œ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ í˜¸ìŠ¤íŒ… ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë„êµ¬ëŠ” ì—ì´ì „íŠ¸ê°€ ì›¹ ê²€ìƒ‰, ë¬¸ì„œ ê²€ìƒ‰, ì™¸ë¶€ ì‹œìŠ¤í…œ ì—°ë™ê³¼ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "## Hosted Tools ë¹„êµ\n",
    "\n",
    "| Tool | Purpose | Service | Key Features |\n",
    "|------|---------|---------|--------------|\n",
    "| **HostedFileSearchTool** | Document/Data Search | Azure AI Search | âœ… Index-based search<br>âœ… Semantic search<br>âœ… Configurable ranking |\n",
    "| **HostedWebSearchTool** | Real-time Web Search | Bing Grounding | âœ… Current information<br>âœ… Source citations<br>âœ… Web grounding |\n",
    "| **Local MCP** | Custom Integrations | Local Server | âœ… Full control<br>âœ… Custom logic<br>âœ… Local resources |\n",
    "| **Hosted MCP** | External Services | Remote Server | âœ… Third-party APIs<br>âœ… Scalable<br>âœ… Managed infrastructure |\n",
    "\n",
    "### [Case 4]ë¥¼ ì‹¤ìŠµí•˜ê¸° ìœ„í•œ ì‚¬ì „ ì¤€ë¹„ ì‚¬í•­:\n",
    "\n",
    "Azure ê³„ì •ì— ë¡œê·¸ì¸ í•©ë‹ˆë‹¤. (Azure CLI ë¡œê·¸ì¸ì€ í„°ë¯¸ë„ì—ì„œ ë¨¼ì € ìˆ˜í–‰í•´ì£¼ì„¸ìš”.)\n",
    "- az login --use-device-code\n",
    "- az account set --subscription \"your-subscription-id\"\n",
    "\n",
    "### í˜„ì¬ ë¡œê·¸ì¸ ìƒíƒœ ë° subscription í™•ì¸\n",
    "- az account show --output table\n",
    "\n",
    "**For Azure AI Search (Case 4.1):**\n",
    "- Azure AI Search ì„œë¹„ìŠ¤ë¥¼ ìœ„í•œ ì¸ë±ì‹±ëœ ë°ì´í„°\n",
    "- Azure AI Projectì˜ Search connection ì„¤ì •\n",
    "- Index name (e.g., \"hotels-sample-index\")\n",
    "\n",
    "**For Bing Grounding (Case 4.2):**\n",
    "- Bing Grounding connection in Azure AI Project\n",
    "- `BING_CONNECTION_NAME` or `BING_CONNECTION_ID` environment variable\n",
    "\n",
    "**For MCP Tools (Case 4.3 & 4.4):**\n",
    "- Model Context Protocol (MCP)ì— ëŒ€í•œ ì´í•´\n",
    "- MCP ì„œë²„ ì„¤ì • (local or hosted)\n",
    "\n",
    "**ë³¸ êµìœ¡ì—ì„œëŠ” Case 4.2 Bing Groundingì„ ì§„í–‰í•©ë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì¼€ì´ìŠ¤ì— ëŒ€í•œ ì†ŒìŠ¤ ì½”ë“œëŠ” [ì›ë³¸ GitHub ë¦¬í¬ì§€í† ë¦¬ì˜ íŒŒì´ì¬ ì½”ë“œ](https://github.com/Azure/agent-innovator-lab/blob/main/0_basic-agent/AgentFramework/1_basic-concept-with-msaf.ipynb)ë¥¼ ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d99553",
   "metadata": {},
   "source": [
    "## ğŸ§ª Case 4.2: HostedWebSearchToolë¥¼ í™œìš©í•œ Bing Grounding\n",
    "---\n",
    "ì‹¤ì‹œê°„ ì›¹ ë°ì´í„°ë¥¼ í™œìš©í•´ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ Bing Search APIë¥¼ ì‚¬ìš©í•œ ì›¹ ê¸°ë°˜ ì²˜ë¦¬ ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c7cff",
   "metadata": {},
   "source": [
    "**Setup:**\n",
    "- Azure AI Project with Bing Search connection\n",
    "- Environment variables: `AZURE_AI_PROJECT_ENDPOINT`, `BING_CONNECTION_NAME`\n",
    "\n",
    "**Key Modules:**\n",
    "- `HostedWebSearchTool` from `agent_framework.azure_ai.tools`\n",
    "- Provides grounded responses with web search results and citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from agent_framework.azure import AzureAIAgentClient, AzureOpenAIChatClient\n",
    "from agent_framework import HostedWebSearchTool\n",
    "from agent_framework import ChatAgent\n",
    "\n",
    "azure_project_endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "azure_ai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "async def bing_grounding_demo():\n",
    "    \"\"\"\n",
    "    Demonstrates using Bing Search API for web grounding to answer questions with real-time web data.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Get Azure AI Project endpoint\n",
    "        bing_connection_id = os.environ.get(\"BING_GROUNDING_CONNECTION_ID\")\n",
    "        \n",
    "        # Create Azure AI Agent client with credential\n",
    "        credential = AzureCliCredential()\n",
    "        \n",
    "        # Create web search tool with Bing connection\n",
    "        web_search_tool = HostedWebSearchTool(\n",
    "            \n",
    "            additional_properties={\n",
    "                \"connection_id\": bing_connection_id,\n",
    "                \"top_k\": 3,  # Get top 3 search results\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        azure_ai_agent_client = AzureAIAgentClient(\n",
    "            async_credential=credential,\n",
    "            project_endpoint=azure_project_endpoint,\n",
    "            model_deployment_name=azure_ai_deployment\n",
    "        )\n",
    "        \n",
    "        # Create agent with web search capability\n",
    "        agent = ChatAgent(\n",
    "            #chat_client=azure_openai_chat_client,\n",
    "            chat_client=azure_ai_agent_client,\n",
    "            name=\"Web Research Assistant\",\n",
    "            instructions=\"You are a helpful research assistant. Use web search to find current information and provide grounded answers with citations.\",\n",
    "            tools=[web_search_tool]\n",
    "        )\n",
    "        \n",
    "        # Test questions that require web search\n",
    "        USER_INPUTS = [\n",
    "            \"ì˜¤ëŠ˜ì˜ ë‚ ì”¨ëŠ” ì–´ë–»ìŠµë‹ˆê¹Œ?\"\n",
    "        ]\n",
    "        \n",
    "        print(\"=== Azure AI Agent with Bing Grounding Search ===\")\n",
    "        print(\"This agent can search the web for current information and provide grounded answers.\\n\")\n",
    "        \n",
    "        # Simulate conversation with the agent\n",
    "        for user_input in USER_INPUTS:\n",
    "            print(f\"User: {user_input}\")\n",
    "            print(\"Agent: \", end=\"\", flush=True)\n",
    "            \n",
    "            # Stream the response for better user experience\n",
    "            async for chunk in agent.run_stream(user_input):\n",
    "                if chunk.text:\n",
    "                    print(chunk.text, end=\"\", flush=True)\n",
    "            print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        \n",
    "        print(\"Web search conversation completed!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "    finally:\n",
    "        # Cleanup: Close Azure AI Agent client if it was created\n",
    "        try:\n",
    "            await azure_ai_agent_client.close()    \n",
    "        except Exception as cleanup_error:\n",
    "            print(f\"Cleanup warning: {cleanup_error}\")\n",
    "\n",
    "await bing_grounding_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee672e3c",
   "metadata": {},
   "source": [
    "## ğŸ§ª Case 4.3: ë¡œì»¬ MCP ì„œë²„ ì—°ë™\n",
    "---\n",
    "ë¡œì»¬ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ Model Context Protocol(MCP) ì„œë²„ì— ì—°ê²°í•´, ì»¤ìŠ¤í…€ ë„êµ¬ë¡œ ì—ì´ì „íŠ¸ ê¸°ëŠ¥ì„ í™•ì¥í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "### ì„¤ì •:\n",
    "\n",
    "- ë¡œì»¬ MCP ì„œë²„ ì‹¤í–‰ (ì˜ˆ: íŒŒì¼ ì‹œìŠ¤í…œ ë„êµ¬, ë°ì´í„°ë² ì´ìŠ¤ ì»¤ë„¥í„° ë“±)\n",
    "- MCP ì„œë²„ URL ë˜ëŠ” ì„¤ì • ì •ë³´\n",
    "- í™˜ê²½ ë³€ìˆ˜: AZURE_OPENAI_ENDPOINT\n",
    "\n",
    "### ì£¼ìš” ëª¨ë“ˆ:\n",
    "\n",
    "- MCP ì„œë²„ì—ì„œ ë„êµ¬ë¥¼ ìë™ íƒìƒ‰Â·ë“±ë¡\n",
    "- MCP ê·œê²©ì„ ì¤€ìˆ˜í•˜ëŠ” ëª¨ë“  ì„œë²„ êµ¬í˜„ê³¼ í•¨ê»˜ ë™ì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from agent_framework.azure import AzureOpenAIChatClient, AzureAIAgentClient\n",
    "from agent_framework import ChatAgent, MCPStreamableHTTPTool\n",
    "\n",
    "\n",
    "async def local_mcp_demo():\n",
    "    \"\"\"\n",
    "    Demonstrates connecting to a local Model Context Protocol (MCP) server \n",
    "    to extend agent capabilities with custom tools.\n",
    "    \n",
    "    This example shows how to use Microsoft Learn MCP server with Azure AI Agent.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create Azure AI Agent client with credential\n",
    "        credential = AzureCliCredential()\n",
    "        \n",
    "        print(\"=== Azure AI Agent with Local MCP Server ===\")\n",
    "        print(\"This agent can use MCP tools to access Microsoft documentation.\\n\")\n",
    "        \n",
    "        # Connect to local MCP server and create agent with MCP tools\n",
    "        async with (\n",
    "            AzureAIAgentClient(\n",
    "                async_credential=credential,\n",
    "                project_endpoint=azure_project_endpoint,\n",
    "                model_deployment_name=azure_ai_deployment\n",
    "            ) as azure_ai_agent_client,\n",
    "            MCPStreamableHTTPTool(\n",
    "                name=\"Local Microsoft Learn MCP\",\n",
    "                url=\"https://learn.microsoft.com/api/mcp\",\n",
    "            ) as mcp_server\n",
    "        ):\n",
    "            # Create agent with MCP tools\n",
    "            agent = ChatAgent(\n",
    "                chat_client=azure_ai_agent_client,\n",
    "                name=\"Local MCP Assistant(AzureAIAgentClient)\",\n",
    "                instructions=\"You are a helpful assistant that can help with Microsoft documentation questions using MCP tools.\",\n",
    "                tools=mcp_server,\n",
    "                store=True\n",
    "            )\n",
    "            \n",
    "            # Test questions that use MCP tools\n",
    "            USER_INPUTS = [\n",
    "                \"How to create an Azure storage account using az cli? response with a simple answer and an example.\",\n",
    "                \"What is Microsoft Agent Framework? response with key concepts and a main python code example.\"\n",
    "            ]\n",
    "            \n",
    "            # Simulate conversation with the agent\n",
    "            for user_input in USER_INPUTS:\n",
    "                print(f\"User: {user_input}\")\n",
    "                print(\"Agent: \", end=\"\", flush=True)\n",
    "                \n",
    "                # Stream the response for better user experience\n",
    "                async for chunk in agent.run_stream(user_input):\n",
    "                    if chunk.text:\n",
    "                        print(chunk.text, end=\"\", flush=True)\n",
    "                print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "            \n",
    "            print(\"MCP tool conversation completed!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "await local_mcp_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe959d",
   "metadata": {},
   "source": [
    "## ğŸ“Š Case 4 ë¹„êµ: Enterprise Tools\n",
    "\n",
    "| Feature | AI Search (4.1) | Bing Grounding (4.2) | Local MCP (4.3) | Hosted MCP (4.4) |\n",
    "|---------|----------------|---------------------|----------------|------------------|\n",
    "| **Tool Type** | `HostedFileSearchTool` | `HostedWebSearchTool` | `MCPClient` | `HostedMCPTool` |\n",
    "| **Client Type** | `AzureAIAgentClient` | `AzureAIAgentClient` | `AzureOpenAIChatClient` | `AzureAIAgentClient` |\n",
    "| **Data Source** | Azure AI Search vector stores | Bing Search API | Local MCP server process | Azure-hosted MCP server |\n",
    "| **Setup Complexity** | Medium (requires vector store) | Low (requires Bing connection) | Medium (requires local server) | Low (requires Azure connection) |\n",
    "| **Use Cases** | Internal document search, knowledge base | Real-time web information | Custom local tools, file system | Enterprise-grade custom tools |\n",
    "| **Authentication** | `DefaultAzureCredential` | `DefaultAzureCredential` | `AzureCliCredential` | `DefaultAzureCredential` |\n",
    "| **Grounding** | Citations from indexed docs | Web citations and sources | N/A (custom tool output) | Depends on MCP server |\n",
    "| **Scalability** | High (Azure managed) | High (Azure managed) | Low (local process) | High (Azure managed) |\n",
    "| **Customization** | Limited to indexed data | Limited to web search | Full (custom MCP tools) | Full (custom MCP tools) |\n",
    "| **Cost** | AI Search + AI Project | Bing API + AI Project | Azure OpenAI only | MCP hosting + AI Project |\n",
    "\n",
    "**Key Takeaways:**\n",
    "- **AI Search (4.1)**: ìì²´ ë¬¸ì„œì™€ ì§€ì‹ ê¸°ë°˜ì„ ì˜ë¯¸ ê²€ìƒ‰ìœ¼ë¡œ íƒìƒ‰í•  ë•Œ ê°€ì¥ ì í•©\n",
    "- **Bing Grounding (4.2)**: ì¶œì²˜ê°€ ëª…ì‹œëœ ì‹¤ì‹œê°„ ì›¹ ì •ë³´ë¥¼ í™œìš©í•  ë•Œ ê°€ì¥ ì í•©\n",
    "- **Local MCP (4.3)**: ë¡œì»¬ ë¨¸ì‹ ì—ì„œ ë§ì¶¤í˜• ë„êµ¬ë¡œ ê°œë°œ ë° í…ŒìŠ¤íŠ¸í•  ë•Œ ê°€ì¥ ì í•©\n",
    "- **Hosted MCP (4.4)**: ì—”í„°í”„ë¼ì´ì¦ˆ ë³´ì•ˆê³¼ í™•ì¥ì„±ì„ ê°–ì¶˜ ë§ì¶¤í˜• ë„êµ¬ì˜ í”„ë¡œë•ì…˜ ë°°í¬ì— ê°€ì¥ ì í•©"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
